# TextFooler

## 1: Word Importance Ranking

通过去掉某个词后再输入到模型中，来判定这个词的重要性

![image-20230214101309480](C:\Users\89528\AppData\Roaming\Typora\typora-user-images\image-20230214101309480.png)

## 2: Word Transformer

- Synonym Extraction:

  选择出50个cosine similarity大于0.7的词

- POS Checking:

  将词性相同的词保留下来

- Semantic Similarity:

  把所有candidates依次加到原句子中，利用USE计算句子相似度，超过某个特定阈值的才保留

- Selection:

  若能puzzle，选择semantic similarity最大的；若不能puzzle，选择I_wi最大的

# BertAttack

## 1: Find Vunerable Words

将每个词依次mask，输入到模型中和原文做差

## 2: Replacement

- 首先给每个词生成top-K的candidates，利用BERT来生成

- 根据词的重要性循环，每次循环中先获取对应的Candidates，此处需要滤过一些词，本文中滤除了虚词和反义词，然后遍历所有candidates，看是否能成功扰动，若能则返回，若不能则返回扰动最大的一项。

# BAE

本文多提出了一个插入新的token。计算重要性的方法是把某个词给去掉而不是mask掉。

获得candidates的方法与BertAttack一致，获得candidates之后第一步也是filter，Replace和Insert都会利用USE计算句子相似度要超过某个阈值，Replace时还要确认词性一致性

选择样本的标准也是一致的

攻击有四种方式：

- BAE-R
- BAE-I：左右皆有可能
- BAE-R/I，二选一
- BAE-R+I，先R再I

# CLARE

定义了三种action，replace，insert（在某个词后面插入一个mask），merge（将某个词和他后面那个词合并成一个mask）。

生成mask位置数据的方法也是利用BERT，Replace加多了一条计算词与词之间相似度，选择让相关概率最小的一项作为最终结果。

首先计算并记录每个词上，三个action哪个影响最大。生成最终集合A。注意此处的action是已经完成了新词生成工作的。

设定一个阈值T，即改变原句子的次数，从A中选择score最高的action，apply到x上，若导致label变化则返回